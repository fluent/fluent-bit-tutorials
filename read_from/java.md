# How to read Java application logs

## Introduction

This article provides a general introduction on how to handle Java logs using
[Fluent Bit](https://fluentbit.io/). It also glances over the issues associated
with container environments like Docker.

## How to Parse Java Application Logs

### Getting Started

Let's first look at the simplest case.

To consume log files generated by a Java application, you need to configure
Fluent Bit to use `in_tail` (in *fluent-bit.conf*) and customize the parser for
your log format (in *parsers.conf*). Here is an example configuration.

**fluent-bit.conf**

```
[Service]
  Parsers_File     /path/to/parsers.conf

[INPUT]
  Name             tail
  Path             /var/log/java.log
  DB               /var/log/fluent-bit/java.db
  Tag              servlet.*
  Multiline        On
  Multiline_Flush  5
  Parser_Firstline java_firstline

[OUTPUT]
  Name             stdout
  Match            *
```

where:

 * `Path`: is where the log file exists.
 * `DB`: is where `in_tail` saves file offsets. With this, you can preserve the read state between restarts.
 * `Multiline`: enables multi-line parsing. See below for why this option is needed.

**parsers.conf**

```
[PARSER]
    Format      regex
    Name        java_firstline
    Regex       ^(?<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) (?<level>\w+) (?<log>.*)
    Time_Format %Y-%m-%d %H:%M:%S,%L
    Time_Keep   On
    Time_Key    time
```

where:

 * `Regex`: defines how each line should be parsed into key-value pairs.
 * `Time_Format`: is a strptime-like format string to parse the time field.

Note that this configuration is set up to parse logs in the following format.

```
2019-04-26 05:56:46,385 INFO Launching application ...
2019-04-26 05:56:46,722 INFO Context initialized.
2019-04-26 05:56:46,425 DEBUG Log file is '/var/log/java.log'
2019-04-26 05:56:47,002 INFO Waiting when the pool is empty
```

If you use a different format for logging, please tweak `Regex` and
`Time_Format` to suit your needs.

### Side Note: Why Multiline?

This is required in order to handle Java's stack trace properly.

The root problem is that Java prints stack traces with multiple lines, using
one line per frame. Here is a typical example of such outputs.

```
2019-04-26 06:36:18.811 ERROR Failed to process a request
java.lang.ArithmeticException: / by zero
    at JavaApp.main(JavaApp.java:14) [?:?]
    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]
    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
    at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
    at com.sun.tools.javac.launcher.Main.execute(Main.java:404) [jdk.compiler:?]
    at com.sun.tools.javac.launcher.Main.run(Main.java:179) [jdk.compiler:?]
    at com.sun.tools.javac.launcher.Main.main(Main.java:119) [jdk.compiler:?]
```

Obviously we need to "combine" these lines to produce a complete event. This is
where the need for `Multiline` and `Parser_Firstline` comes in. A simple
`Parser` option cannot handle such records.

## How to Handle Java Application Logs on Docker

The difficulty arises when you containerize your Java application.
[Docker](https://www.docker.com/) is the most widely used container platform.
Docker allows to save guest application's log in the host machine, but by
default it converts guest's log lines into a custom format.

This section explains how to collect Java logs through Docker.

### Step 1: Make Java log in JSON

The most easiest way to consume Java application logs through Docker is to
teach Java loggers to use JSON format.

For example, if you use [log4j2](https://logging.apache.org/log4j/2.x/) for
logging, you can put something like below in your `log4j2.xml`.

```
<?xml version="1.0" encoding="UTF-8"?>
<Configuration level="info">
  <Appenders>
    <Console name="console" target="SYSTEM_OUT">
      <JsonLayout complete="false" compact="true" eventEol="true" />
    </Console>
  </Appenders>
  <Loggers>
    <Root level="info">
      <AppenderRef ref="console"/>
    </Root>
  </Loggers>
</Configuration>
```

Or if you use [logback](https://logback.qos.ch/), you can use the Logback JSON
extension in the contrib project.

```
<?xml version="1.0" encoding="UTF-8"?>
<Configuration level="info">
  <Appender name="console" class="ch.qos.logback.core.ConsoleAppender">
    <Encoder class="ch.qos.logback.core.encoder.LayoutWrappingEncoder">
      <Layout class="ch.qos.logback.contrib.json.classic.JsonLayout">
        <JsonFormatter class="ch.qos.logback.contrib.jackson.JacksonJsonFormatter">
          <PrettyPrint>false</PrettyPrint>
        </JsonFormatter>
        <AppendLineSeparator>true</AppendLineSeparator>
      </Layout>
    </Encoder>
  </Appender>
  <Root level="info">
    <Appender-Ref ref="console"/>
  </Root>
</Configuration>
```

For details, please read the official manual for [log4j](https://logging.apache.org/log4j/2.x/manual/layouts.html#JSONLayout)
or [logback](https://github.com/qos-ch/logback-contrib/wiki/JSON).

### Step 2: Configure Fluent Bit

After configuring your Java logger, you can consume logs using the following
configuration.

**fluent-bit.conf**

```
[Service]
  Parsers_File     /etc/fluent-bit/parsers.conf

[INPUT]
  Name             tail
  Path             /var/lib/docker/containers/*/*.log
  DB               /var/log/fluent-bit/java.db
  Tag              servlet.*
  Parser           docker

[FILTER]
  Name             parser
  Match            servlet.*
  Key_Name         log
  Parser           json

[OUTPUT]
  Name             stdout
  Match            *
```

The `docker` and `json` parsers used in the above example are defined in
*parsers.conf* bundled in the standard distribution of Fluent Bit, so you do
not need to define them yourself (just make sure that `Parsers_File` points
to it).

### Side Note: Why Parse Twice?

You may have noticed that the configuration above parses each log line twice:
Once in `in_tail` (using `docker` parser) and once in `filter_parser` (using
`json` parser).

But why? A typical log line in a Docker log file looks like below.

```
{"stream":"stdout","time":"2019-05-07T04:10:50.852051516Z","log":"{\"timeMillis\":1557202250850,\"thread\":\"main\",\"level\":\"INFO\",\"loggerName\":\"app\",\"message\":\"Context initialized.\",\"endOfBatch\":false,\"loggerFqcn\":\"org.apache.logging.log4j.spi.AbstractLogger\",\"threadId\":1,\"threadPriority\":5}\r\n"}
```

So the "log" field in each line contains another JSON object as a string. This
is the original log data emitted by your Java application, and what the second
`json` parser deserializes.

The resulting record would look like this:

```
{
    "timeMillis"=>1557202250850,
    "thread"=>"main",
    "level"=>"INFO",
    "loggerName"=>"app",
    "message"=>"Context initialized.",
    "endOfBatch"=>false,
    "loggerFqcn"=>"org.apache.logging.log4j.spi.AbstractLogger",
    "threadId"=>1,
    "threadPriority"=>5
}
```

### Side Note: How to Use Fluentd Logging Driver

Another way to transfer logs to Fluent Bit is to use [Fluentd logging driver](https://docs.docker.com/config/containers/logging/fluentd/)
provided by Docker. Here is a configuration example for such a setup.

**fluent-bit.conf**

```
[Service]
  Parsers_File     /etc/fluent-bit/parsers.conf

[INPUT]
  Name             forward
  Port             24224

[FILTER]
  Name             parser
  Match            servlet.*
  Key_Name         log
  Parser           json

[OUTPUT]
  Name             stdout
  Match            *
```

After running Fluent Bit with this configuration, you need to tell Docker
where to send log data.

```
$ docker run --log-driver=fluentd --log-opt fluentd-address=192.168.1.2:24224 my-java-servlet
```

The biggest win of this strategy is that you can forward logs into Fluent Bit
running on another host. This approach makes a lot of sense if you launches
a number of Docker containers simultaneously.

The downside of this approach is that it makes `docker logs` non-fanctional,
So if you want to use the CLI interface to fetch application logs, you'd better
stick to the `json-file` driver and `in_tail` (Also the Fluentd driver has
[some known stability issue](https://github.com/moby/moby/issues/32567), so
please test enough before deploying).

## Next Step

* If you want to tweak the parser for your log format, read [Parsers manual](https://docs.fluentbit.io/manual/parser).
* If you want to send records to other hosts, see the list of [Output plugins](https://docs.fluentbit.io/manual/output).
